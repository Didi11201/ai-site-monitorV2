import os
import yaml
import time
import json
import csv
import aiohttp
import asyncio
import google.generativeai as genai
from datetime import datetime

# === åŠ è½½é…ç½®æ–‡ä»¶ ===
CONFIG_PATH = "config.yml"
with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    config = yaml.safe_load(f)

API_KEY = os.getenv("GEMINI_API_KEY") or config.get("gemini_api_key")
OUTPUT_DIR = config.get("output_dir", "results")
os.makedirs(OUTPUT_DIR, exist_ok=True)

print("ğŸš€ [å¯åŠ¨ç›‘æµ‹ç¨‹åº]")
print(f"åŠ è½½é…ç½®æ–‡ä»¶: {CONFIG_PATH}")
print(f"ç›®æ ‡ç½‘ç«™æ•°é‡: {len(config['sites'])}")
print(f"å…³é”®è¯åˆ—è¡¨: {config['keywords']}")

# === Gemini åˆå§‹åŒ–ä¸æµ‹è¯• ===
print("\nğŸ” [æ£€æµ‹ Gemini API è¿æ¥çŠ¶æ€]")

if not API_KEY:
    print("âŒ æœªæ‰¾åˆ° Gemini API Keyï¼Œè¯·æ£€æŸ¥ GitHub Secrets æˆ– config.ymlã€‚")
    exit(1)

try:
    genai.configure(api_key=API_KEY)
    model = genai.GenerativeModel(config.get("gemini_model", "gemini-1.5-flash"))
    test_response = model.generate_content("Say hi if Gemini is working.")
    print("âœ… Gemini API æ­£å¸¸è¿æ¥ï¼Œæµ‹è¯•å›å¤:", test_response.text[:100])
except Exception as e:
    print("âŒ Gemini è¿æ¥å¤±è´¥:", e)
    exit(1)

# === å¼‚æ­¥ç½‘ç«™ç›‘æµ‹é€»è¾‘ ===
async def fetch_site(session, url, timeout):
    try:
        async with session.get(url, timeout=timeout) as resp:
            text = await resp.text()
            return text[:config["text_limit"]]
    except Exception as e:
        print(f"âš ï¸ {url} è®¿é—®å¤±è´¥: {e}")
        return ""

async def analyze_site(model, url, html, keywords):
    """è°ƒç”¨ Gemini åˆ†æç½‘ç«™æ˜¯å¦åŒ…å«å…³é”®è¯"""
    if not html.strip():
        return False, []

    prompt = f"""
ä½ æ˜¯ä¸€ä½ç½‘ç«™ä¿ƒé”€å†…å®¹æ£€æµ‹åŠ©æ‰‹ã€‚
ä»¥ä¸‹æ˜¯ç½‘ç«™ HTML å†…å®¹ï¼Œè¯·åˆ¤æ–­æ˜¯å¦åŒ…å«ä»¥ä¸‹å…³é”®è¯ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ï¼š
{keywords}

HTML:
{html[:2000]}
"""

    try:
        response = model.generate_content(prompt)
        text = response.text.lower()
        found = [kw for kw in keywords if kw.lower() in text]
        return bool(found), found
    except Exception as e:
        print(f"âš ï¸ Gemini åˆ†æ {url} æ—¶å‡ºé”™: {e}")
        return False, []

async def monitor_sites():
    timeout = aiohttp.ClientTimeout(total=config.get("timeout", 15))
    results = []
    total_found = 0

    async with aiohttp.ClientSession() as session:
        for site in config["sites"]:
            url = site["url"]
            print(f"\nğŸŒ æ­£åœ¨æ£€æµ‹: {url}")

            html = await fetch_site(session, url, timeout)
            has_promo, found_keywords = await analyze_site(model, url, html, config["keywords"])
            total_found += int(has_promo)

            results.append({
                "site": url,
                "has_promo": has_promo,
                "found_keywords": ", ".join(found_keywords),
                "checked_at": datetime.utcnow().isoformat()
            })

            if has_promo:
                print(f"âœ… {url} æ£€æµ‹åˆ°å…³é”®è¯: {found_keywords}")
            else:
                print(f"âŒ {url} æœªå‘ç°ä¿ƒé”€å…³é”®è¯")

    print(f"\nğŸ¯ æ£€æµ‹å®Œæˆï¼Œæ€»è®¡ {len(results)} ä¸ªç½‘ç«™ï¼Œæ£€æµ‹åˆ° {total_found} ä¸ªæœ‰ä¿ƒé”€å†…å®¹ã€‚")

    # === ä¿å­˜ç»“æœ ===
    json_path = os.path.join(OUTPUT_DIR, "results.json")
    csv_path = os.path.join(OUTPUT_DIR, "results.csv")

    with open(json_path, "w", encoding="utf-8") as jf:
        json.dump(results, jf, ensure_ascii=False, indent=2)

    with open(csv_path, "w", newline="", encoding="utf-8") as cf:
        writer = csv.DictWriter(cf, fieldnames=results[0].keys())
        writer.writeheader()
        writer.writerows(results)

    print(f"\nğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_DIR}/results.json å’Œ results.csv")

# === ä¸»ç¨‹åºå…¥å£ ===
if __name__ == "__main__":
    asyncio.run(monitor_sites())
